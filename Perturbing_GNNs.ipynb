{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perturbing_GNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "elJ8J8nF2L4A"
      },
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-geometric\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize(h, color):\n",
        "    z = TSNE(n_components=2).fit_transform(out.detach().cpu().numpy())\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_cqGcE2Xcv"
      },
      "source": [
        "#I. Defining perturbations of the adjacency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq90JHvi2WYM"
      },
      "source": [
        "#### Teh dropout function already has a lot of the modalities that we want\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch_geometric as tg\n",
        "from torch_sparse import coalesce\n",
        "\n",
        "def filter_adj(row, col, edge_attr, mask):\n",
        "    return row[mask], col[mask], None if edge_attr is None else edge_attr[mask]\n",
        "\n",
        "def drop_edges(edge_index, n_nodes, edge_attr=None, p=0.5, force_undirected=False,\n",
        "                num_nodes=None\n",
        "               ):\n",
        "    r\"\"\"Randomly drops edges from the adjacency matrix\n",
        "    :obj:`(edge_index, edge_attr)` with probability :obj:`p` using samples from\n",
        "    a Bernoulli distribution.\n",
        "\n",
        "    Args:\n",
        "        edge_index (LongTensor): The edge indices.\n",
        "        edge_attr (Tensor, optional): Edge weights or multi-dimensional\n",
        "            edge features. (default: :obj:`None`)\n",
        "        p (float, optional): Dropout probability. (default: :obj:`0.5`)\n",
        "        force_undirected (bool, optional): If set to :obj:`True`, will either\n",
        "            drop or keep both edges of an undirected edge.\n",
        "            (default: :obj:`False`)\n",
        "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
        "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
        "        training (bool, optional): If set to :obj:`False`, this operation is a\n",
        "            no-op. (default: :obj:`True`)\n",
        "    \"\"\"\n",
        "\n",
        "    if p < 0. or p > 1.:\n",
        "        raise ValueError('Dropout probability has to be between 0 and 1, '\n",
        "                         'but got {}'.format(p))\n",
        "\n",
        "    if p == 0.0:\n",
        "        return edge_index, edge_attr\n",
        "\n",
        "    N = num_nodes\n",
        "    row, col = edge_index\n",
        "\n",
        "    if force_undirected:\n",
        "        row, col, edge_attr = filter_adj(row, col, edge_attr, row < col)\n",
        "    mask = edge_index.new_full((row.size(0), ), 1 - p, dtype=torch.float)\n",
        "    mask = torch.bernoulli(mask).to(torch.bool)\n",
        "\n",
        "    row, col, edge_attr = filter_adj(row, col, edge_attr, mask)\n",
        "\n",
        "    if force_undirected:\n",
        "        edge_index = torch.stack(\n",
        "            [torch.cat([row, col], dim=0),\n",
        "             torch.cat([col, row], dim=0)], dim=0)\n",
        "    else:\n",
        "        edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "    return edge_index, edge_attr   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrgeGZV_2oyW"
      },
      "source": [
        "def drop_nb_edges(edge_index, n_edges2delete, edge_attr=None, force_undirected=False,\n",
        "                num_nodes=None, connectedness_constraint = True, \n",
        "                drop_random=True, drop_strategy = \"degree\"\n",
        "               ):\n",
        "    r\"\"\"Randomly drops a number edges from the adjacency matrix, whilst ensuring\n",
        "    that the graph remains connected\n",
        "    :obj:`(edge_index, edge_attr)` with probability :obj:`p` using samples from\n",
        "    a Bernoulli distribution.\n",
        "\n",
        "    Args:\n",
        "        edge_index (LongTensor): The edge indices.\n",
        "        edge_attr (Tensor, optional): Edge weights or multi-dimensional\n",
        "            edge features. (default: :obj:`None`)\n",
        "        p (float, optional): Dropout probability. (default: :obj:`0.5`)\n",
        "        force_undirected (bool, optional): If set to :obj:`True`, will either\n",
        "            drop or keep both edges of an undirected edge.\n",
        "            (default: :obj:`False`)\n",
        "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
        "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
        "        training (bool, optional): If set to :obj:`False`, this operation is a\n",
        "            no-op. (default: :obj:`True`)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if n_edges2delete == 0.0:\n",
        "        return edge_index, edge_attr\n",
        "\n",
        "    if  num_nodes == None: N = edge_index.max().item()\n",
        "    else:  N = num_nodes\n",
        "    row, col = edge_index\n",
        "    degree_seq = [torch.sum(row == k).tolist() for k in np.arange(num_nodes)]\n",
        "\n",
        "    if force_undirected:\n",
        "        row, col, edge_attr = filter_adj(row, col, edge_attr, row < col)\n",
        "    \n",
        "    #mask = edge_index.new_full((row.size(0), ), 1 - p, dtype=torch.float)\n",
        "    mask = edge_index.new_full((row.size(0), ), True, dtype=torch.bool)\n",
        "    if drop_random:\n",
        "      delete_edges = np.random.choice(np.arange(len(row)), size=n_edges2delete )\n",
        "    else:\n",
        "      #### drop edges with higher probability if the nodes is well connected\n",
        "      p = [ min([degree_seq[col[i]], degree_seq[col[i]]]) for i in np.arange(len(row))]\n",
        "      delete_edges = np.random.choice(np.arange(len(row)), size=n_edges2delete, p = p )\n",
        "      \n",
        "    mask[delete_edges] = False\n",
        "  \n",
        "    row2, col2, edge_attr2 = filter_adj(row, col, edge_attr, mask)\n",
        "\n",
        "    if force_undirected:\n",
        "        edge_index = torch.stack(\n",
        "            [torch.cat([row2, col2], dim=0),\n",
        "             torch.cat([col2, row2], dim=0)], dim=0)\n",
        "    else:\n",
        "        edge_index = torch.stack([row2, col2], dim=0)\n",
        "    ##### Unsures that the matrix remains connected\n",
        "\n",
        "    if connectedness_constraint:\n",
        "      row2, col2 = edge_index\n",
        "      degree_seq2 = [torch.sum(row2 == k).tolist() for k in np.arange(num_nodes\n",
        "                                                                      )]\n",
        "      unconnected_nodes = np.where(np.array(degree_seq2) < 1)[0]\n",
        "      #print(unconnected_nodes)\n",
        "      if len(unconnected_nodes)>0:\n",
        "          for i in unconnected_nodes:\n",
        "            initial_edge = np.hstack([col[np.where(row == i)[0]],row[np.where(col == i)[0]]])\n",
        "            uu = np.random.choice(initial_edge)\n",
        "            edge_index = torch.hstack([edge_index, torch.tensor([[i, uu ],[uu, i ]]) ] )\n",
        "    \n",
        "    #row2, col2 = edge_index\n",
        "    #degree_seq2 = [torch.sum(row2 == k).tolist() for k in np.arange(num_nodes)]\n",
        "    #unconnected_nodes = np.where(np.array(degree_seq2) < 1)[0]\n",
        "    #print(unconnected_nodes)\n",
        "    return edge_index, edge_attr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhQ7azHQ4RP4"
      },
      "source": [
        "#### TO DO: add perturbations targeted at some location of the graph (using tg.utils.k_hop_subgraph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRZagUot2rH3"
      },
      "source": [
        "# II. Defining random graph structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6sEHOYW7_Jq"
      },
      "source": [
        "#### TO DO: generate synthetic graphs\n",
        "#### Let's use networkx\n",
        "import networkx as nx\n",
        "def SyntheticData(num_nodes, n_classes, graph_generator_type=\"planted_partition\",\n",
        "                  p_in=0.5, p_out=0.1):\n",
        "  x= torch.ones((num_nodes, n_classes +10)) ### Node features\n",
        "  nn. int(num_nodes/n_classes)\n",
        "  if graph_generator_type==\"planted_partition\":\n",
        "    G = nx.planted_partition_graph(nn, n_classes,\n",
        "                                   p_in, p_out, seed=42\n",
        "                                   )\n",
        "    labels = torch.tensor(np.concatenate([[u] * 10  for u in np.arange(7)]), dtype=int)\n",
        "  dd = tg.utils.convert.from_networkx(G)\n",
        "  edge_index= dd.edge_index ### Edge Index\n",
        "  edge_attr=None ### Edge features\n",
        "  y = labels ### Node labels\n",
        "  return tg.data.Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ByT4kcK8lDe"
      },
      "source": [
        "tg."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv1qpXDP2guB"
      },
      "source": [
        "# III. Assessing the performance on the graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ9EOETL28ba"
      },
      "source": [
        "### a. Defining the GCN pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LUxML6n3B5H"
      },
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=16)\n",
        "print(model)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnbb6N5g355i"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "def GCN_pipeline(data, edge_index):\n",
        "    model = GCN(hidden_channels=16)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    def train():\n",
        "          model.train()\n",
        "          optimizer.zero_grad()  # Clear gradients.\n",
        "          out = model(data.x, edge_index)  # Perform a single forward pass.\n",
        "          loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "          loss.backward()  # Derive gradients.\n",
        "          optimizer.step()  # Update parameters based on gradients.\n",
        "          return loss\n",
        "\n",
        "    def test():\n",
        "          model.eval()\n",
        "          out = model(data.x, edge_index)\n",
        "          pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "          test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
        "          test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
        "          return test_acc\n",
        "\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "    \n",
        "    return test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnv5CecU3_ZY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBByhOzo3Cgk"
      },
      "source": [
        "### b. Defining the MLP pipeline (for comparison)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYDeUwAn27e9"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "\n",
        "def MLP_pipeline(data):\n",
        "  model = MLP(hidden_channels=16)\n",
        "  criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
        "\n",
        "  def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()  # Clear gradients.\n",
        "        out = model(data.x)  # Perform a single forward pass.\n",
        "        loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "        loss.backward()  # Derive gradients.\n",
        "        optimizer.step()  # Update parameters based on gradients.\n",
        "        return loss\n",
        "\n",
        "  def test():\n",
        "        model.eval()\n",
        "        out = model(data.x)\n",
        "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "        test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
        "        test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
        "        return test_acc\n",
        "\n",
        "  for epoch in range(1, 201):\n",
        "      loss = train()\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "  return test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av5WxdAK3Lmx"
      },
      "source": [
        "### c. Run experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsQu1ix2wi1"
      },
      "source": [
        "##### \n",
        "b = 0 \n",
        "mlp_res = []\n",
        "gnn_res =[]\n",
        "while b < 100:\n",
        "  edge_index2,_ = drop_nb_edges(data.edge_index, 600, edge_attr=None, force_undirected=True,\n",
        "                num_nodes=data.num_nodes, connectedness_constraint = True)\n",
        "  \n",
        "  mlp_res += [MLP_pipeline(data)]\n",
        "  gnn_res += [GCN_pipeline(data, edge_index2)]\n",
        "  b += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}